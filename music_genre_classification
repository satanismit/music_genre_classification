# import libraries :
import os
import matplotlib.pyplot as plt
import librosa
import numpy as np
import tensorflow as tf

# Visualizing single audio :
path1='genres_original/rock/rock.00002.wav'  
path2='genres_original/blues/blues.00000.wav'
path3='genres_original/classical/classical.00000.wav'
path4='genres_original/country/country.00002.wav'
path5='genres_original/disco/disco.00000.wav'
path6='genres_original/hiphop/hiphop.00000.wav'
path7='genres_original/jazz/jazz.00005.wav'
path8='genres_original/metal/metal.00006.wav'
path9='genres_original/pop/pop.00007.wav'
path10='genres_original/reggae/reggae.00002.wav'

y_rock, sr1=librosa.load(path1,sr=44410)
y_blues, sr2=librosa.load(path2,sr=44410)
y_classical, sr3=librosa.load(path3,sr=44410)
y_country, sr4=librosa.load(path4,sr=44410)
y_disco, sr5=librosa.load(path5,sr=44410)
y_hiphop, sr6=librosa.load(path6,sr=44410)
y_jazz, sr7=librosa.load(path7,sr=44410)
y_metal, sr8=librosa.load(path8,sr=44410)
y_pop, sr9=librosa.load(path9,sr=44410)
y_reggae, sr10=librosa.load(path10,sr=44410)



print(len(y))
print("sampling rate:",sr)

plt.figure(figsize=(14,6))


# to display audio signal in the form of graph ( amplitude vs time)
print("Rock audio : ")
librosa.display.waveshow(y_rock,sr=sr1)

plt.figure(figsize=(14,6))
librosa.display.waveshow(y_blues,sr=sr2)
print("Blues audio : ")
plt.show()

plt.figure(figsize=(14,6))
print("Classical  audio : ")
librosa.display.waveshow(y_classical,sr=sr3)

plt.figure(figsize=(14,6))
print("Country audio : ")
librosa.display.waveshow(y_country,sr=sr4)

plt.figure(figsize=(14,6))
print("Disco audio : ")
librosa.display.waveshow(y_disco,sr=sr5)

plt.figure(figsize=(14,6))
print("Hiphop  audio : ")
librosa.display.waveshow(y_hiphop,sr=sr6)

plt.figure(figsize=(14,6))
print("jazz audio : ")
librosa.display.waveshow(y_jazz,sr=sr7)

plt.figure(figsize=(14,6))
print("Metal audio : ")
librosa.display.waveshow(y_metal,sr=sr8)

plt.figure(figsize=(14,6))
print("Pop audio : ")
librosa.display.waveshow(y_pop,sr=sr9)
plt.show()

path='genres_original/pop/pop.00046.wav'
y, sr=librosa.load(path,sr=44410)
plt.figure(figsize=(14,6))
print("Pop2 audio : ")
librosa.display.waveshow(y_pop,sr=sr9)
plt.show()


plt.figure(figsize=(14,6))
print("Reggae audio : ")
librosa.display.waveshow(y_reggae,sr=sr10)


# Doing visualization on chunks of Audio : 

file_path='genres_original/rock/rock.00002.wav'
y, sr=librosa.load(file_path,sr=None) # beacuse we use original sampling rate 

# no of samples in 30 sec audio file 
print(len(y),y.shape) # (661794,1)

# define duration of chunks and overlap 
chunks_duration=4
overlap_duration=2

# convert duration to sample
chunks_samples=chunks_duration*sr
overlap_samples=overlap_duration*sr

print(chunks_samples)
print(overlap_samples)

#calculate the no of chunks 
num_chunks=int(np.ceil((len(y)-chunks_samples)/(chunks_samples-overlap_samples)))+1
print('no of chunks in 30 sec audio file:',num_chunks)

# iterate all chunks 
for i in range(num_chunks):
    start=i*(chunks_samples-overlap_samples)
    end=start+chunks_samples
    chunk=y[start:end]
    plt.figure(figsize=(6,5))
    librosa.display.waveshow(chunk,sr=sr)
    plt.show()

# Melspectrogram Visualization :

file_path='genres_original/rock/rock.00002.wav'
y, sr=librosa.load(file_path,sr=44410)

# melspectrogram of entire audio :
def plot_melspectrogram(y,sr):
    # compute melspectrogram :
    spectrogram= librosa.feature.melspectrogram(y=y, sr=sr)
    # convert to decible:
    spectrogram_db=librosa.power_to_db(spectrogram, ref=np.max)

    plt.figure(figsize=(10,4))
    librosa.display.specshow(spectrogram_db,sr=sr, x_axis="time", y_axis="mel")
    plt.colorbar(format='%2.0f db')
    plt.title("Spectrogram")
    plt.tight_layout()
    plt.show()

plot_melspectrogram(y,sr)
def count_num_chunks(chunk_dur, overlap_dur,sr):
    # convert duration to sample
    chunks_samples=chunk_dur*sr
    overlap_samples=overlap_dur*sr
    
    print("Chunks Samples:",chunks_samples)
    print("Overlap Samples:",overlap_samples)
    
    #calculate the no of chunks 
    num_chunks=int(np.ceil((len(y)-chunks_samples)/(chunks_samples-overlap_samples)))+1
    print('no of chunks in 30 sec audio file:',num_chunks)
    return num_chunks

def plot_melspectrogram_chunks(y,sr):
    
    num_chunks=count_num_chunks(4,2,sr)
    # iterate all chunks 
    for i in range(num_chunks):
        start=i*(chunks_samples-overlap_samples)
        end=start+chunks_samples
        chunk=y[start:end]
        print("Melspectrogram : ", i+1)
        plot_melspectrogram(chunk,sr)

plot_melspectrogram_chunks(y,sr)

# Data Preprocessing - Final
#define your folder structure
data_dir = "./genres_original"
classes = ['blues', 'classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']

from tensorflow.image import resize
#Load and preprocess audio data
def load_and_preprocess_data(data_dir,classes,target_shape=(150,150)):
    data=[]
    labels=[]

    for i_class,class_name in enumerate(classes):
        class_dir = os.path.join(data_dir,class_name)
        print("Processing--",class_name)
        for filename in os.listdir(class_dir):
            if filename.endswith('.wav'):
                file_path = os.path.join(class_dir,filename)
                audio_data,sample_rate = librosa.load(file_path,sr=None)
                #Performing Preprocessing
                #define the duration of each chunk and overlap
                chunk_duration = 4
                overlap_duration = 2
                
                #Convert duration to sample
                chunk_samples = chunk_duration * sample_rate
                overlap_samples = overlap_duration * sample_rate
                
                #Calculate the number of chunks
                num_chunks = int(np.ceil((len(audio_data)-chunk_samples)/(chunk_samples-overlap_samples)))+1
                
                #iterate over each chunks
                for i in range(num_chunks):
                    #Calculate start and end indices of the chunk
                    start = i*(chunk_samples-overlap_samples)
                    end = start+chunk_samples
                    #Extract the chunk audio
                    chunk = audio_data[start:end]
                    #Melspectrogram part
                    mel_spectrogram = librosa.feature.melspectrogram(y=chunk,sr=sample_rate)
                    #Resize matrix based on provided target shape
                    mel_spectrogram = resize(np.expand_dims(mel_spectrogram,axis=-1),target_shape)
                    #Append data to list
                    data.append(mel_spectrogram)
                    labels.append(i_class)
    #Return
    return np.array(data),np.array(labels)

data,labels = load_and_preprocess_data(data_dir,classes)

